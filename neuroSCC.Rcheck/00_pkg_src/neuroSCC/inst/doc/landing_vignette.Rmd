---
title: "landing_vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{landing_vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(neuroSCC)
```

# Introduction

This vignette guides you through the initial data preparation steps necessary to use the **neuroSCC** package for analyzing neuroimaging data with Simultaneous Confidence Corridors (SCC).

---

# 1. Loading and Inspecting Neuroimaging Data

We'll begin by loading a sample PET neuroimaging file included with the package and inspecting its structure.

```{r}
niftiFile <- system.file("extdata", "syntheticControl1.nii.gz", package = "neuroSCC")

# Load and clean data using neuroCleaner
petData <- neuroCleaner(niftiFile)

# Inspect the data
head(petData)
str(petData)
```

---

# 2. Creating a Database from Multiple PET Images

Now, let's demonstrate how to create a structured database using multiple PET files available in the package.

```{r}
# Create database for control subjects
controlPattern <- "^syntheticControl.*\\.nii.gz$"
databaseControls <- databaseCreator(pattern = controlPattern, control = TRUE, quiet = FALSE)

# Inspect the created database
head(databaseControls)
table(databaseControls$CN_number)
```

---

# 3. Creating the Data Matrix

We'll transform the PET database into a matrix format suitable for SCC analysis.

```{r}
# Create matrix for Z-slice 35
matrixControls <- matrixCreator(databaseControls, paramZ = 35, quiet = FALSE)

# Inspect matrix structure
dim(matrixControls)
str(matrixControls)
```

---

# 4. Normalizing the Data Matrix

Normalization adjusts for global intensity differences between subjects.

```{r}
# Perform mean normalization
normalizedMatrix <- meanNormalization(matrixControls, returnDetails = FALSE)

```

---

# 5. Extracting Contours for Triangulation

Contours from the neuroimage are used to set boundaries for SCC computations.

```{r, fig.alt="Contours for brain imaging data"}
# Extract contours from sample data
contours <- neuroContour(niftiFile, paramZ = 35, levels = 0, plotResult = TRUE)

# Check contours structure
length(contours)
str(contours[[1]])
```

---

# 6. Conditional Triangulation Setup (optional)

The triangulation step requires the external `Triangulation` package, currently not on CRAN. Ensure you have this package installed. If not, install it using:

```r
remotes::install_github("FIRST-Data-Lab/Triangulation")
```

Conditional example for triangulation:

```{r, fig.alt="Delaunay triangulations for brain imaging data", eval = requireNamespace("ImageSCC", quietly = TRUE)}

if (!requireNamespace("Triangulation", quietly = TRUE)) {
  cat("Triangulation package is not installed.\nInstall it using: remotes::install_github('FIRST-Data-Lab/Triangulation')\n")
} else {
  # Perform triangulation with the first contour
  mesh <- Triangulation::TriMesh(n = 15, contours[[1]])
  
  # Inspect mesh
  print(mesh[["V"]][1:10, ])
  print(mesh[["Tr"]][1:10, ])
}

```

---

# What's Next?

You're now ready to perform Simultaneous Confidence Corridor analyses:

- Single-group SCC analysis (see `one_group_scc` vignette)
- Two-group comparison SCC (see `two_group_comparison` vignette)
- Single patient vs. group analysis (see `one_vs_group` vignette)

Feel free to explore these vignettes to continue your analysis journey with neuroSCC.
